{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7a813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361d81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4e7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape is ', train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()\n",
    "\n",
    "# each feature has some missing values so we need to work on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a2e45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes\n",
    "\n",
    "# Object columns need transformation ['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Name', 'VIP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.select_dtypes('float64').skew()\n",
    "\n",
    "#  Those columns are right skewed ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'Vrdeck']\n",
    "#  apply np.log to those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if the target variable is balanced or not\n",
    "train['Transported'].value_counts()\n",
    "\n",
    "# Yes, It is almost balanced as we can see.\n",
    "# But we need to transform this column from bool to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ca51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = train.corr()\n",
    "\n",
    "# Poor correlations between the columns and the target variable.\n",
    "# We need to work the feature engineering alittle bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9237b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.hist(figsize=(13, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cf78af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.plot(kind='density', subplots=True, layout=(3,3), sharex=False, figsize=(13, 10))\n",
    "\n",
    "# What the hell is going on with those columns !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91feee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.plot(kind='box', subplots=True, layout=(3,3), sharex=False, figsize=(13, 10))\n",
    "\n",
    "# There is something really weird with the numerical columns except Age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89616af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the Transported column\n",
    "mapping = {True:1, False:0}\n",
    "train['Transported'] = train['Transported'].map(mapping)\n",
    "train['Transported']  = train['Transported'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fec5030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation matrix\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,7,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(train.select_dtypes(['float64', 'int']).columns.values)\n",
    "ax.set_yticklabels(train.select_dtypes(['float64', 'int']).columns.values)\n",
    "\n",
    "# Poor correlation between the columns and the target column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69c6b57",
   "metadata": {},
   "source": [
    "# Now it's time to go through the data preprocessing step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da76b197",
   "metadata": {},
   "source": [
    "## Creating some new features as part of feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849ea478",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"Deck\", \"Num\", \"Side\"]] = (  # Create two new features\n",
    "    train[\"Cabin\"]           # from the Policy feature\n",
    "    .str                         # through the string accessor\n",
    "    .split(\"/\", expand=True)     # by splitting on \" \"\n",
    "                                 # and expanding the result into separate columns\n",
    ")\n",
    "train[[\"Cabin\", \"Deck\", \"Num\", \"Side\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7358ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"Group\", \"Group_Size\"]] = (  # Create two new features\n",
    "    train[\"PassengerId\"]           # from the Policy feature\n",
    "    .str                         # through the string accessor\n",
    "    .split(\"_\", expand=True)     # by splitting on \" \"\n",
    "                                 # and expanding the result into separate columns\n",
    ")\n",
    "train[['PassengerId', 'Group', 'Group_Size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e56df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New feature\n",
    "train['Solo']=(train['Group_Size'] == 1).astype(int)  \n",
    "# test['Solo']=(test['Group'] == 1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cf8e5d",
   "metadata": {},
   "source": [
    "### Handling the missing values and encoding the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling and encoding the CryoSleep column\n",
    "mapping = {'Europe':1, 'Earth':2, 'Mars':3}\n",
    "train['HomePlanet'] = train['HomePlanet'].map(mapping)\n",
    "train['HomePlanet'] = train['HomePlanet'].fillna(2)\n",
    "train['HomePlanet']  = train['HomePlanet'].astype(int)\n",
    "\n",
    "\n",
    "# filling and encoding the CryoSleep column\n",
    "mapping = {True:1, False:0}\n",
    "train['CryoSleep'] = train['CryoSleep'].map(mapping)\n",
    "train['CryoSleep'] = train['CryoSleep'].fillna(0)\n",
    "train['CryoSleep']  = train['CryoSleep'].astype(int)\n",
    "\n",
    "# filling and encoding the VIP column\n",
    "mapping = {True:1, False:0}\n",
    "train['VIP'] = train['VIP'].map(mapping)\n",
    "train['VIP'] = train['VIP'].fillna(0)\n",
    "train['VIP']  = train['VIP'].astype(int)\n",
    "\n",
    "\n",
    "# Filling nan values of the ShoppingMall \n",
    "filling_num = round(train['ShoppingMall'].mean())\n",
    "train['ShoppingMall'] = train['ShoppingMall'].fillna(filling_num)\n",
    "\n",
    "\n",
    "# the unique values of this columns are alot to encode by hand. So we will use sklearn LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train['Cabin'])\n",
    "filling_num = train['Cabin'].mode()\n",
    "train['Cabin'] = encoder.transform(train['Cabin'])\n",
    "train['Cabin'] = train['Cabin'].fillna(filling_num)\n",
    "train['Cabin'] = train['Cabin'].astype(int)\n",
    "\n",
    "\n",
    "# filling the VRDeck column\n",
    "filling_num = round(train['VRDeck'].mean())\n",
    "train['VRDeck'] = train['VRDeck'].fillna(filling_num)\n",
    "\n",
    "\n",
    "# filling the FoodCourt column\n",
    "filling_num = round(train['FoodCourt'].mean())\n",
    "train['FoodCourt'] = train['FoodCourt'].fillna(filling_num)\n",
    "\n",
    "\n",
    "# filling the FoodCourt column\n",
    "filling_num = round(train['Spa'].mean())\n",
    "train['Spa'] = train['Spa'].fillna(filling_num)\n",
    "\n",
    "# filling and encoding the CryoSleep column\n",
    "mapping = {'TRAPPIST-1e':1, 'PSO J318.5-22':2, '55 Cancri e':3}\n",
    "train['Destination'] = train['Destination'].map(mapping)\n",
    "train['Destination'] = train['Destination'].fillna(1)\n",
    "train['Destination']  = train['Destination'].astype(int)\n",
    "# train['Destination'].unique()\n",
    "\n",
    "# filling the RoomService column\n",
    "filling_num = round(train['RoomService'].mean())\n",
    "train['RoomService'] = train['RoomService'].fillna(filling_num)\n",
    "\n",
    "\n",
    "# filling the RoomService column\n",
    "filling_num = train['Age'].mode()\n",
    "train['Age'] = train['Age'].fillna(24)\n",
    "\n",
    "cols = ['Solo', 'Group', 'Group_Size', \"Deck\", \"Num\", \"Side\"]\n",
    "for col in cols:\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(train[col])\n",
    "    filling_num = train[col].mode()\n",
    "    train[col] = encoder.transform(train[col])\n",
    "    train[col] = train[col].fillna(filling_num)\n",
    "    train[col] = train[col].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821452d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.plot(kind='box', subplots=True, sharex=False, legend=True, figsize=(20, 20), layout=(6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4938d346",
   "metadata": {},
   "source": [
    "### Reducing the skewness by applying the np.log1p function two times to the ment columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a490765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.select_dtypes('float64').skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e820b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.drop(['PassengerId', 'Name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe99cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skewed_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "# for col in skewed_cols:\n",
    "#     train[col] = train[col].apply(np.log1p)\n",
    "#     train[col] = train[col].apply(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8e3da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('Transported', axis=1)\n",
    "y = train['Transported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebdb1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "kfold = KFold(10, random_state=0, shuffle=True)\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "score = cross_val_score(model, X, y, cv=kfold, scoring='roc_auc')\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9d14db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "matrix = confusion_matrix(y_test, pred)\n",
    "print(matrix)\n",
    "\n",
    "score = cross_val_score(model, X, y, cv=kfold, scoring='roc_auc')\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95248ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# models = [\n",
    "#     ('Knn', KNeighborsClassifier(15)),\n",
    "#     ('svc', SVC(probability=True)),\n",
    "#     ('Dtc', DecisionTreeClassifier()),\n",
    "#     ('Rdf', RandomForestClassifier()),\n",
    "# \t('adb', AdaBoostClassifier()),\n",
    "#     ('grdb', GradientBoostingClassifier()),\n",
    "#     ('Gaus', GaussianNB()),\n",
    "#     ('LDA', LinearDiscriminantAnalysis()),\n",
    "#     ('QDA', QuadraticDiscriminantAnalysis()),\n",
    "#     ('LogR', LogisticRegression(max_iter=1000)),\n",
    "#     ('MLP', MLPClassifier(max_iter=300))\n",
    "# ]\n",
    "# # evaluate each model in turn\n",
    "# results = []\n",
    "# names = []\n",
    "# scoring = 'accuracy'\n",
    "# for name, model in models:\n",
    "#     kfold = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "#     cv_results = cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "#     results.append(cv_results)\n",
    "#     names.append(name)\n",
    "#     print(name, cv_results.mean(), cv_results.std())\n",
    "# # boxplot algorithm comparison\n",
    "# fig = plt.figure()\n",
    "# fig.suptitle('Algorithm Comparison')\n",
    "# ax = fig.add_subplot(111)\n",
    "# plt.boxplot(results)\n",
    "# ax.set_xticklabels(names)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f44c6e",
   "metadata": {},
   "source": [
    "## After comparing those algorithms we found that the best are:\n",
    "1. RandomForestClassifier\n",
    "2. AdaBoosingClassifier\n",
    "3. GradientBoostingClassirier\n",
    "4. LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25426ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "base_estm = [('GRD', GradientBoostingClassifier()),\n",
    "             ('RDFC', RandomForestClassifier()),\n",
    "             ('ADA', AdaBoostClassifier())]\n",
    "level_estm = LinearDiscriminantAnalysis()\n",
    "\n",
    "stacking_models = StackingClassifier(estimators=base_estm, final_estimator=level_estm)\n",
    "\n",
    "X = train.drop('Transported', axis=1)\n",
    "y = train['Transported']\n",
    "# X = X[['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'CryoSleep', 'Deck', 'Cabin', 'Group']]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "# stacking_models.fit(X, y)\n",
    "\n",
    "# print(stacking_models.score(X_test, y_test))\n",
    "# score = stacking_models.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71d3b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import chi2\n",
    "# create feature union\n",
    "features = []\n",
    "features.append(('pca', PCA(n_components=3)))\n",
    "features.append(('select_best', SelectKBest(score_func=chi2, k=11)))\n",
    "feature_union = FeatureUnion(features)\n",
    "# create pipeline\n",
    "estimators = []\n",
    "estimators.append(('feature_union', feature_union))\n",
    "# estimators.append('scaler', StandardScaler())\n",
    "estimators.append(('Stacking', stacking_models))\n",
    "model = Pipeline(estimators)\n",
    "\n",
    "# evaluate pipeline\n",
    "kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "results = cross_val_score(model, X, y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c9fc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random 8 pca 16 k 300 n_estimators.\n",
    "# GRDBC 12 pca 15 k  Without piplines is better.\n",
    "# ADAB 11 pca 15 k \n",
    "# LDA 12 pca 5 k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422928dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"Group\", \"Group_Size\"]] = (  # Create two new features\n",
    "    test[\"PassengerId\"]           # from the Policy feature\n",
    "    .str                         # through the string accessor\n",
    "    .split(\"_\", expand=True)     # by splitting on \" \"\n",
    "                                 # and expanding the result into separate columns\n",
    ")\n",
    "# test[['PassengerId', 'Group', 'Group_Size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New feature\n",
    "test['Solo']=(test['Group_Size'] == 1).astype(int)  \n",
    "# test['Solo']=(test['Group'] == 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c7300",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"Deck\", \"Num\", \"Side\"]] = (  # Create two new features\n",
    "    test[\"Cabin\"]           # from the Policy feature\n",
    "    .str                         # through the string accessor\n",
    "    .split(\"/\", expand=True)     # by splitting on \" \"\n",
    "                                 # and expanding the result into separate columns\n",
    ")\n",
    "# test[[\"Cabin\", \"Deck\", \"Num\", \"Side\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90868422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling and encoding the CryoSleep column\n",
    "mapping = {'Europe':1, 'Earth':2, 'Mars':3}\n",
    "test['HomePlanet'] = test['HomePlanet'].map(mapping)\n",
    "test['HomePlanet'] = test['HomePlanet'].fillna(2)\n",
    "test['HomePlanet']  = test['HomePlanet'].astype(int)\n",
    "\n",
    "\n",
    "# filling and encoding the CryoSleep column\n",
    "mapping = {True:1, False:0}\n",
    "test['CryoSleep'] = test['CryoSleep'].map(mapping)\n",
    "test['CryoSleep'] = test['CryoSleep'].fillna(0)\n",
    "test['CryoSleep']  = test['CryoSleep'].astype(int)\n",
    "\n",
    "# filling and encoding the VIP column\n",
    "mapping = {True:1, False:0}\n",
    "test['VIP'] = test['VIP'].map(mapping)\n",
    "test['VIP'] = test['VIP'].fillna(0)\n",
    "test['VIP']  = test['VIP'].astype(int)\n",
    "\n",
    "# Filling nan values of the ShoppingMall \n",
    "filling_num = round(test['ShoppingMall'].mean())\n",
    "test['ShoppingMall'] = test['ShoppingMall'].fillna(filling_num)\n",
    "\n",
    "# the unique values of this columns are alot to encode by hand. So we will use sklearn LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(test['Cabin'])\n",
    "filling_num = test['Cabin'].mode()\n",
    "test['Cabin'] = encoder.transform(test['Cabin'])\n",
    "test['Cabin'] = test['Cabin'].fillna(filling_num)\n",
    "test['Cabin'] = test['Cabin'].astype(int)\n",
    "\n",
    "# filling the VRDeck column\n",
    "filling_num = round(train['VRDeck'].mean())\n",
    "test['VRDeck'] = test['VRDeck'].fillna(filling_num)\n",
    "\n",
    "# filling the FoodCourt column\n",
    "filling_num = round(test['FoodCourt'].mean())\n",
    "test['FoodCourt'] = test['FoodCourt'].fillna(filling_num)\n",
    "\n",
    "# filling the FoodCourt column\n",
    "filling_num = round(test['Spa'].mean())\n",
    "test['Spa'] = test['Spa'].fillna(filling_num)\n",
    "\n",
    "# filling and encoding the CryoSleep column\n",
    "mapping = {'TRAPPIST-1e':1, 'PSO J318.5-22':2, '55 Cancri e':3}\n",
    "test['Destination'] = test['Destination'].map(mapping)\n",
    "test['Destination'] = test['Destination'].fillna(1)\n",
    "test['Destination']  = test['Destination'].astype(int)\n",
    "# train['Destination'].unique()\n",
    "\n",
    "# filling the RoomService column\n",
    "filling_num = round(test['RoomService'].mean())\n",
    "test['RoomService'] = test['RoomService'].fillna(filling_num)\n",
    "\n",
    "# filling the RoomService column\n",
    "filling_num = test['Age'].mode()\n",
    "test['Age'] = test['Age'].fillna(24)\n",
    "\n",
    "cols = ['Solo', 'Group', 'Group_Size', \"Deck\", \"Num\", \"Side\"]\n",
    "for col in cols:\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(test[col])\n",
    "    filling_num = test[col].mode()\n",
    "    test[col] = encoder.transform(test[col])\n",
    "    test[col] = test[col].fillna(filling_num)\n",
    "    test[col] = test[col].astype(int)\n",
    "\n",
    "#Droping Name column\n",
    "test = test.drop('Name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257ab947",
   "metadata": {},
   "outputs": [],
   "source": [
    "PassengerId = test['PassengerId']\n",
    "test.drop('PassengerId', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54832e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = test[['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'CryoSleep', 'Deck', 'Cabin', 'Group']]\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4c723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Submission File \n",
    "GBCsubmission = pd.DataFrame({ 'PassengerId': PassengerId,\n",
    "                            'Transported': predictions })\n",
    "GBCsubmission['Transported'] = GBCsubmission['Transported'] .astype(bool)\n",
    "GBCsubmission.to_csv(\"best_score.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bfa827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load, dump\n",
    "\n",
    "file_name = 'Titanic_Spaceship_Best_Stacking_models.sav'\n",
    "dump(model, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d064eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load(file_name)\n",
    "result = loaded_model.score(X, y)\n",
    "print(\"the score of the loaded model is \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cc11c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
